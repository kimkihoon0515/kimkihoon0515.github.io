<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-12-04T21:00:27+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">배운 것들을 정리하고 기록하는 블로그</title><subtitle>최대한 꾸준히 글을 작성하는 것이 목표.</subtitle><author><name>김기훈</name><email>tega1996@naver.com</email></author><entry><title type="html">Kubernetes 인프런 강의 정리</title><link href="http://localhost:4000/devops/kubernetes-%EA%B0%95%EC%9D%98/" rel="alternate" type="text/html" title="Kubernetes 인프런 강의 정리" /><published>2022-12-04T00:00:00+09:00</published><updated>2022-12-04T00:00:00+09:00</updated><id>http://localhost:4000/devops/kubernetes-%EA%B0%95%EC%9D%98</id><content type="html" xml:base="http://localhost:4000/devops/kubernetes-%EA%B0%95%EC%9D%98/"><![CDATA[<h1 id="kubernetes-강의-정리">Kubernetes 강의 정리</h1>

<h1 id="pod">Pod</h1>

<p>쿠버네티스에서 관리하는 가장 작은 배포 단위이다.</p>

<p>도커는 컨테이너를 만들고 쿠버네티스는 Pod를 만든다.</p>

<p>Pod는 한 개 또는 여러 개의 컨테이너를 포함한다.</p>

<h2 id="pod-생성-분석">Pod 생성 분석</h2>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/018b41b5-0fdf-4aa6-9bf1-ec81b70fc5ad/Untitled.png" alt="Untitled" /></p>

<p>Pod는 다음과 같이 클러스터 안에 Pod가 있고 그 안에 컨테이너가 있는 형식이다.</p>

<p>Pod이 생성되는 과정은 다음과 같다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8a08b0de-ae6e-4933-b6e0-2518b7cdfd60/Untitled.png" alt="Untitled" /></p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>는 API 서버를 감시하면서 할당되지 않은 <code class="language-plaintext highlighter-rouge">Pod</code> 유무를 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>는 할당되지 않은 <code class="language-plaintext highlighter-rouge">Pod</code>를 감지하고 적절한 노드에 할당한다.</li>
  <li>노드에 설치된 <code class="language-plaintext highlighter-rouge">kubelet</code>은 자신의 노드에 할당된 <code class="language-plaintext highlighter-rouge">Pod</code>가 있는지 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubelet</code>은 <code class="language-plaintext highlighter-rouge">Scheduler</code>에 의해 자신에게 할당된 Pod의 정보를 확인하고 컨테이너를 생성한다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubelet</code>은 자신에게 할당된 <code class="language-plaintext highlighter-rouge">Pod</code>의 상태를 <code class="language-plaintext highlighter-rouge">API</code> 서버에 전달한다.</li>
</ol>

<h2 id="yaml-파일">YAML 파일</h2>

<table>
  <thead>
    <tr>
      <th>정의</th>
      <th>설명</th>
      <th>예</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>version</td>
      <td>오브젝트 버전</td>
      <td>v1, app/v1, networking.k8s.io/v1</td>
    </tr>
    <tr>
      <td>kind</td>
      <td>종류</td>
      <td>Pod, ReplicaSet, Deployment, Service</td>
    </tr>
    <tr>
      <td>metadata</td>
      <td>메타데이터</td>
      <td>name과 label, annotaion(주석)으로 구성</td>
    </tr>
    <tr>
      <td>spec</td>
      <td>상세명세</td>
      <td>리소스 종류마다 다름</td>
    </tr>
  </tbody>
</table>

<h1 id="replicaset">ReplicaSet</h1>

<p>Pod를 단독으로 만들면 그 Pod이 죽었을 때 자동으로 복귀되지 않는다. 이러한 Pod를 정해진 수만큼 복제하고 관리하는 것이 ReplicaSet이다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/68ebb360-208a-4282-9106-773c599cdceb/Untitled.png" alt="Untitled" /></p>

<p>ReplicaSet은 label을 체크해서 원하는 수의 Pod이 없으면 새로운 Pod을 생성한다.</p>

<table>
  <thead>
    <tr>
      <th>정의</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>spec.selector</td>
      <td>label 체크 조건</td>
    </tr>
    <tr>
      <td>spec.replicas</td>
      <td>원하는 Pod의 개수</td>
    </tr>
    <tr>
      <td>spec.template</td>
      <td>생성할 Pod의 명세</td>
    </tr>
  </tbody>
</table>

<p>ReplicaSet은 다음과 같이 동작한다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3ce00d9d-b993-4a24-80d8-9c4c72d490a0/Untitled.png" alt="Untitled" /></p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">ReplicaSet Controller</code>는 ReplicaSet조건을 감시하면서 현재 상태와 원하는 상태가 다른지 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">ReplicaSet Controller</code>가 원하는 상태가 되도록 Pod를 생성하거나 제거한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>는 API 서버를 감시하면서 할당되지 않은 Pod이 있는지 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>는 할당되지 않은 새로운 Pod을 감지하고 적절한 노드에 배치</li>
  <li>이후 노드는 기존대로 동작한다.</li>
</ol>

<p>ReplicaSet은 ReplicaSet Controller가 관리하고 Pod의 할당은 Scheduler가 관리한다.</p>

<h2 id="정리">정리</h2>

<p>ReplicaSet은 Pod의 개수를 유지하는 역할을 담당한다. label을 통해 Pod를 체크하기 때문에 겹치지 않게 신경써야하나다.</p>

<p>실전에서는 Deployment가 ReplicaSet을 이용하고 주로 Deployment를 사용한다.</p>

<h1 id="deployment">Deployment</h1>

<p>쿠버네티스에서 가장 널리 사용되는 오브젝트이다. ReplicaSet을 이용하여 Pod을 업데이트하고 이력을 관리하여 롤백하거나 특정 버전으로 돌아갈 수 있다.</p>

<p>버전을 업데이트하면 새로운 ReplicaSet을 생성하고 해당 ReplicaSet이 새로운 버전의 Pod을 생성한다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/81d100ee-bf04-47ff-92e0-f487921727d3/Untitled.png" alt="Untitled" /></p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">Deployment Controller</code>는 Deployment 조건을 감시하면서 현재 상태와 원하는 상태가 다른지 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Deployment Controller</code>가 원하는 상태가 되도록 <code class="language-plaintext highlighter-rouge">ReplicaSet</code> 설정한다.</li>
  <li><code class="language-plaintext highlighter-rouge">ReplicaSet Controller</code>는 ReplicaSet조건을 감시하면서 현재 상태와 원하는 상태가 다른지 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">ReplicaSet Controller</code>가 원하는 상태가 되도록 <code class="language-plaintext highlighter-rouge">Pod</code>을 생성하거나 제거한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>는 API서버를 감시하면서 할당되지 않은 <code class="language-plaintext highlighter-rouge">Pod</code>이 있는지 체크한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>는 할당되지 않은 새로운 Pod을 감지하고 적절한 <code class="language-plaintext highlighter-rouge">노드</code>에 배치한다.</li>
</ol>

<p>Deployment는 Deployment Controller가 관리하고 ReplicaSet과 Pod는 기존 Controller와 Scheduler가 관리한다.</p>

<h1 id="service">Service</h1>

<p>Pod는 자체 IP를 가지고 다른 Pod과 통신할 수 있지만 쉽게 사라지기 때문에 직접 통신하는 대신 별도의 고정된 IP를 가진 서비스를 만들고 그 서비스를 통해 접근하는 방식을 사용한다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d333ca05-fdde-4ac5-820c-1e00d2ccd14b/Untitled.png" alt="Untitled" /></p>

<p>같은 클러스터에서 생성된 Pod이라면 도메인 이름으로 Pod에 접근할 수 있다.</p>

<p>ClusterIP 서비스의 설정은 다음과 같다.</p>

<table>
  <thead>
    <tr>
      <th>정의</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>spec.ports.port</td>
      <td>서비스가 생성할 Port</td>
    </tr>
    <tr>
      <td>spec.ports.targetPort</td>
      <td>서비스가 접근할 Pod의 Port (기본: port랑 동일)</td>
    </tr>
    <tr>
      <td>spec.selector</td>
      <td>서비스가 접근할 Pod의 label 조건</td>
    </tr>
  </tbody>
</table>

<h2 id="service-생성-흐름">Service 생성 흐름</h2>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a4356484-e85f-4220-8e35-ff1024549ab7/Untitled.png" alt="Untitled" /></p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">Endpoint Controller</code>는 <code class="language-plaintext highlighter-rouge">Service</code>와 <code class="language-plaintext highlighter-rouge">Pod</code>을 감시하면서 조건에 맞는 Pod의 IP를 수집한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Endpoint Controller</code>가 수집한 IP를 가지고 <code class="language-plaintext highlighter-rouge">Endpoint</code> 생성한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Kube-Proxy</code>는 <code class="language-plaintext highlighter-rouge">Endpoint</code> 변화를 감시하고 노드의 iptables을 설정한다.</li>
  <li><code class="language-plaintext highlighter-rouge">CoreDNS</code>는 <code class="language-plaintext highlighter-rouge">Service</code>를 감시하고 서비스 이릅과 IP를 <code class="language-plaintext highlighter-rouge">CoreDNS</code>에 추가한다.</li>
</ol>

<p>여기서 <code class="language-plaintext highlighter-rouge">iptables</code>는 커널 레벨의 네트워크 도구이고 <code class="language-plaintext highlighter-rouge">CoreDNS</code>는 빠르고 편리하게 사용할 수 있는 클러스트 내부용 도메인 네임 서버이다. 각각의 역할은 iptables 설정으로 여러 IP에 트래픽을 전달하고 CoreDNS를 이용하여 IP 대신 도메인 이름을 사용한다.</p>

<p><code class="language-plaintext highlighter-rouge">ClusterIP</code>는 클러스터 내부에서만 접근이 가능하고 <code class="language-plaintext highlighter-rouge">NodePort</code>는 외부에서도 접근이 가능하다.</p>

<p>그리고 이 <code class="language-plaintext highlighter-rouge">NodePort</code>는 3000~32767번까지의 포트를 사용한다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ce4918be-6455-40f5-b3a7-1472db17573c/Untitled.png" alt="Untitled" /></p>

<p>하지만 <code class="language-plaintext highlighter-rouge">NodePort</code>도 단점이 있는데 바로 노드가 사라졌을 때 자동으로 다른 노드를 통해 접근이 불가능하다는 점이다. 예를 들면, 3개의 노드가 있다면 이 3개중에 아무 노드로 접근해도 NodePort로 연결할 수 있지만 어떤 노드가 살아 있는지는 알 수 없다.</p>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dc16ccbd-1a17-43c6-b56a-f7f6514fa6b8/Untitled.png" alt="Untitled" /></p>

<p>자동으로 살아 있는 노드에 접근하기위해 모든 노드를 보고 있는 <code class="language-plaintext highlighter-rouge">Load Balancer</code> 가 필요하다. 브라우저는 NodePort에 직접 요청을 보내는 것이 아니라 Load Balancer에 요청하고 Load Balancer가 알아서 살아있는 Node에 접근하는식으로 NodePort의 단점을 없앨 수 있다.</p>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="DevOps" /><summary type="html"><![CDATA[Kubernetes 강의 정리]]></summary></entry><entry><title type="html">Nginx</title><link href="http://localhost:4000/devops/nginx/" rel="alternate" type="text/html" title="Nginx" /><published>2022-11-14T00:00:00+09:00</published><updated>2022-11-14T00:00:00+09:00</updated><id>http://localhost:4000/devops/nginx</id><content type="html" xml:base="http://localhost:4000/devops/nginx/"><![CDATA[<h1 id="정적-페이지와-동적-페이지">정적 페이지와 동적 페이지</h1>

<p><img width="706" alt="image" src="https://user-images.githubusercontent.com/63439911/201676532-8e2a761f-1124-44ce-97d7-7098470c8fc3.png" /></p>

<p>웹페이지는 위의 이미지처럼 웹 주소 url을 가지고 통신 규칙 http에 맞게 요청하면 알맞은 내용 html을 응답받는다. 하지만 이처럼 단순한 클라이언트와 웹 서버로는 정적인 페이지밖에 처리하지 못하는 한계가 있다.</p>

<p>이러한 html의 한계를 극복하기 위해 application을 활용한 것이 Web Application이다.</p>

<p>더 나아가서 보안강화와 장애 극복을 가능하게 하는 것을 Web Application Server 줄여서 WAS라고 부른다.</p>

<h2 id="static-page">Static Page</h2>

<p>Web Server는 파일 경로와 이름을 받아서 일치하는 file contents를 반환한다.</p>

<p>항상 동일한 페이지를 반환한다.</p>

<p>html, css, image 파일과 같이 컴퓨터에 저장되어 있는 파일들을 반환해준다.</p>

<p><img width="706" alt="image" src="https://user-images.githubusercontent.com/63439911/201676643-3b1df4b6-c80a-4c9f-8549-226e02304b63.png" /></p>

<h2 id="dynamic-pages">Dynamic Pages</h2>

<p>동적 페이지는 동적인 Contents들을 반환한다.</p>

<p>웹 서버에 의해서 실행되는 프로그램을 통해 만들어진 결과물이다.</p>

<p><img width="705" alt="image" src="https://user-images.githubusercontent.com/63439911/201676746-b65261ee-e3e3-4ed0-aa19-75fb549cea37.png" /></p>

<h1 id="web-server-vs-was">Web Server vs WAS</h1>

<h2 id="web-server">Web Server</h2>

<p>웹 서버는 클라이언트로부터 HTTP요청을 받아 HTML 문서나 각종 리소스를 전달하는 컴퓨터이다.</p>

<p><img width="552" alt="image" src="https://user-images.githubusercontent.com/63439911/201676855-1ee10f2c-30c6-42c6-8a68-de906dd73872.png" /></p>

<p>아래의 두 가지 기능 중 요청에 따라 적절하게 선택하여 수행한다.</p>

<ul>
  <li>기능 1
    <ul>
      <li>정적인 컨텐츠를 제공한다.</li>
      <li>WAS를 거치지 않고 바로 자원을 제공한다.</li>
    </ul>
  </li>
  <li>기능 2
    <ul>
      <li>동적인 컨텐츠 제공을 위한 요청을 전달한다.</li>
      <li>클라이언트의 요청을 WAS에 보내고 WAS가 처리한 결과를 클라이언트에 전달한다.</li>
      <li>클라이언트는 일반적으로 웹 브라우저이다.</li>
    </ul>
  </li>
</ul>

<p>웹 서버에는 Apache Server와 Nginx가 있는데 각각의 특성은 다음과 같다.</p>

<ul>
  <li>Apache Server : Linux 뿐 아니라 Windows 환경에서도 운용 가능</li>
  <li>Nginx : 가벼움과 높은 성능을 목표로 하고 웹 서버, 프록시 기능을 가짐</li>
</ul>

<h2 id="was">WAS</h2>

<p>WAS는 웹 어플리케이션과 서버 환경을 만들어 동작시키는 기능을 제공하는 소프트웨어 미들웨어 프레임워크이다.</p>

<p><img width="705" alt="image" src="https://user-images.githubusercontent.com/63439911/201676961-7689ebec-9c17-4fa9-bc63-4cce5037eb9f.png" /></p>

<p>WAS는 Web Server와 Web Container(JSP, Servlet)으로 이루어져 있다.</p>

<p>Web Server와는 다르게 Web Container를 갖는다는 점이 특징이며 HTML같은 정적인 페이지에서 처리를 할 수 없는 DB 조회, 비즈니스 로직 같은 동적 컨텐츠를 제공한다.</p>

<p>현업에서 하는 프로젝트를 보면 WAS와 Web Server를 분리하는데 그렇게 하여 얻을 수 있는 장점은 다음과 같다.</p>

<p><img width="656" alt="image" src="https://user-images.githubusercontent.com/63439911/201677079-f53d4149-65c0-465e-be4c-36735f36cded.png" /></p>

<ol>
  <li>기능을 분리하여 서버의 부하를 방지할 수 있다.
    <ul>
      <li>WAS는 페이지를 만들기 위한 다양한 로직을 처리하는데 단순히 정적인 컨텐츠를 WAS에서 제공하면 리소스 낭비가 되어 작업이 지연될 수 있다.</li>
    </ul>
  </li>
  <li>보안 강화
    <ul>
      <li>SSL에 암호화 처리에 Web Server를 사용한다.</li>
      <li>Web Server를 앞단에 두어서 중요한 정보가 담긴 DB나 로직까지 전파되지 못하게 한다.</li>
    </ul>
  </li>
  <li>여러 대의 WAS를 연결이 가능하다.
    <ul>
      <li>Load Balancing 이 가능하게 된다.</li>
      <li>
        <p>장애극복이 가능하다.</p>

        <p><img width="442" alt="image" src="https://user-images.githubusercontent.com/63439911/201677165-66d77758-e0af-4310-97dd-14bbf4187aca.png" /></p>
      </li>
    </ul>
  </li>
  <li>다른 종류의 WAS로 서비스가 가능하다.
    <ul>
      <li>하나의 서버에서 PHP App과 JAVA App을 함께 사용이 가능하다.</li>
    </ul>
  </li>
</ol>

<h1 id="proxy란">Proxy란?</h1>

<p>보안상의 문제로 직접 통신을 주고받을 수 없는 두 PC 사이의 통신을 할 때 직접 하지 않고 중간에서 중계를 해주는 개념을 프록시라고 한다.</p>

<p><img width="627" alt="image" src="https://user-images.githubusercontent.com/63439911/201677327-386042d5-c640-415a-906e-90df47d6773f.png" /></p>

<p>프록시 서버는 서버가 어디에 위치하느냐에 따라서 포워드와 리버스 프록시로 나뉜다.</p>

<h2 id="forward-proxy">Forward Proxy</h2>

<p>클라이언트에서 서버로 리소스를 요청할 때 직접 요청하는 것이 아니라 프록시 서버를 거쳐서 요청하게 된다. 이럴 경우에는 서버에서 받는 IP는 클라이언트가 아닌 프록시 서버의 IP이기 때문에 서버는 클라이언트가 누군지 알 수 없게 된다. 결과적으로 서버에게 클라이언트가 누구인지 감추는 역할을 한다.</p>

<p>Forward Proxy는 대개 캐싱 기능이 있으므로 자주 사용되는 컨텐츠라면 월등한 성능 향상을 가져올 수 있으며 정해진 사이트만 연결하게 설정하는 등 웹 사용 환경을 제한할 수 있으므로 보안이 매우 중요한 기업 환경 등에서 많이 사용한다.</p>

<p><img width="705" alt="image" src="https://user-images.githubusercontent.com/63439911/201677452-6dd4a4e9-9669-45a4-8ab1-ac15d90303c7.png" /></p>

<ul>
  <li>클라이언트가 서버에게 요청할 때 직접 서버에 접근하는것이 아니고 포워드 프록시 서버에 요청을 하면 포워드 프록시 서버가 해당 서버에 접근하여 요청을 전달하고 결과를 클라이언트에 전달해주는 방식</li>
  <li>포워드 프록시는 캐시 기능을 사용하기 때문에 캐시 서버로 활용하여 성능 향상을 시킬 수 있다.</li>
  <li>자주 사용되는 자원을 캐시에 저장해놓기 때문에 해당 자원 요청이 온다면 서버에게 갈 필요 없이 프록시 서버 자체에서 처리가 가능하다.</li>
  <li>클라이언트가 서버를 직접 접근하지 못하기 때문에 보안성이 향상된다.</li>
</ul>

<h2 id="reverse-proxy">Reverse Proxy</h2>

<p>리버스 프록시는 포워드 프록시와 반대되는 개념이다. 애플리케이션 서버의 앞에 위치하며 클라이언트가 서버를 요청할 때 리버스 프록시를 호출하고 리버스 프록시가 서버로부터 응답을 전달받아 다시 클라이언트에게 전송하는 역할을 한다.</p>

<p>이 때 클라이언트는 애플리케이션 서버를 직접 호출하는것이 아니라 서버를 통해 호출하기 때문에 리버스 프록시는 애플리케이션 서버를 감추는 역할을 하게 된다.</p>

<p><img width="703" alt="image" src="https://user-images.githubusercontent.com/63439911/201677536-8c488bf7-2d2d-4990-9c0f-ee9f5cf5b710.png" /></p>

<ul>
  <li>클라이언트가 서버에게 요청할 때 직접 서버에 접근하는 것이 아니라 리버스 프록시 서버가 이 요청들을 받아서 내부 서비스에 접근하여 요청을 전달하고 결과를 클라이언트에게 전달해주는 방식</li>
  <li>클라이언트는 내부 서버를 접근하지 못하기 때문에 보안과 성능을 샹상할 수 있다.</li>
  <li>여러 내부 서버를 둘 수 있어서 로드 밸런싱이나 트래픽 분산이 가능하다.</li>
  <li>포워드 프록시와는 반대로 내부 서버는 클라이언트를 알지만 클라이언트는 프록시를 통해 내부 서버를 접근하기 때문에 내부 서버를 알 지 못한다.</li>
</ul>

<h1 id="nginx">Nginx</h1>

<p>Nginx란 WAS를 도와주는 비동기 이벤트 기반구조의 경량화 웹 서버 프로그램이다.</p>

<p>클라이언트로부터 요청을 받았을 때 요청에 맞는 정적 파일을 응답해주는 HTTP Web Server로 활용되기도 하고 또는 Reverse Proxy Server로 활용하여 WAS의 부하를 줄일 수 있는 로드밸런서 역할을 하기도 한다.</p>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="DevOps" /><summary type="html"><![CDATA[정적 페이지와 동적 페이지]]></summary></entry><entry><title type="html">GitLab</title><link href="http://localhost:4000/mlops/gitlab/" rel="alternate" type="text/html" title="GitLab" /><published>2022-11-07T00:00:00+09:00</published><updated>2022-11-07T00:00:00+09:00</updated><id>http://localhost:4000/mlops/gitlab</id><content type="html" xml:base="http://localhost:4000/mlops/gitlab/"><![CDATA[<h1 id="gitlab">Gitlab</h1>

<h1 id="gitlab-cicd-시작">GitLab CI/CD 시작</h1>

<ol>
  <li>Job을 실행할 수 있는 Runner가 있는지 확인한다. 없을 경우 GitLab Runner를 설치하고 인스턴스, 프로젝트 또는 그룹에 대한 러너를 등록한다.</li>
  <li>.gitlab-ci.yml 파일을 레포지토리의 루트에 생성한다. 이 파일은 CI/CD Job을 정의하는 곳이다.</li>
</ol>

<p>파일을 레포지토리에 커밋하면 러너가 Job을 실행한다. Job의 결과는 파이프라인에 표시된다.</p>

<h2 id="runner를-사용할-수-있는지-확인">Runner를 사용할 수 있는지 확인</h2>

<p>GitLab에서 Runner는 CI/CD Job을 실행하는 에이전트이다. Gitlab 인스턴스의 모든 프로젝트에서 사용할 수 있는 공유 러너를 포함하여 프로젝트에서 사용할 수 있는 러너가 이미 있을 수 있다.</p>

<p>만약 사용가능한 러너를 보고 싶으면</p>

<ul>
  <li>Settings &gt; CI/CD로 이동하여 Runners를 확장한다.</li>
</ul>

<p>UI의 Runners 페이지에 러너가 없다면 사용자 또는 시스템 관리자가 GitLab Runner를 설치하고 하나 이상의 러너를 등록해야 한다.</p>

<p>CI/CD를 테스트 하는 경우, 로컬 컴퓨터에 Gitlab Runner를 설치하고 러너를 등록할 수 있다. CI/CD Job이 실행되면 로컬 컴퓨터에서 실행된다.</p>

<h2 id="gitlab-ciyml-파일-생성">.gitlab-ci.yml 파일 생성</h2>

<p>.gitlab-ci.yml 파일은 GitLab CI/CD에 대한 특정 지침을 구성하는 YAML 파일이다. 이 파일에서는 다음 2가지를 정의한다.</p>

<ul>
  <li>러너가 실행해야 하는 작업의 구조와 순서</li>
  <li>특정 조건이 발생할 때 러너가 내려야 하는 결정</li>
</ul>

<p>master에 커밋하면 통일한 테스트 슈트 (Test Suite)를 실행하고 애플리케이션도 게시하려고 한다.</p>

<p>.gitlab-ci.yml 파일을 생성하려면 :</p>

<ol>
  <li>Project overview &gt; Details로 이동한다.</li>
  <li>파일 목록 위에서 커밋할 브랜치를 선택하고 New File을 선택한다.</li>
  <li>파일 이름으로 .gitlab-ci.yml 을 입력하고 파일 내용을 작성한다.</li>
  <li>Commit changes 버튼을 누른다.</li>
  <li>파이프라인 시작</li>
</ol>

<h2 id="파이프라인-및-작업-상태-보기">파이프라인 및 작업 상태 보기</h2>

<p>파이프라인을 보려면 CI/CD &gt; Pipelines로 이동한다.</p>

<p><img src="https://user-images.githubusercontent.com/63439911/200330704-ac82f12c-c3ed-490a-82be-73e0e622bae2.png" alt="image" /></p>

<p>다음과 같이 3가지 파이프라인이 표시되어야 한다.</p>

<h1 id="cicd-pipelines">CI/CD Pipelines</h1>

<p>파이프라인은 지속적 통합, 제공 및 배포의 최상위 구성 요소이다.</p>

<p>파이프라인은 다음으로 구성된다.</p>

<ul>
  <li>수행할 작업을 정의하는 Jobs. (코드를 컴파일하거나 테스트 하는 작업)</li>
  <li>작업을 실행할 시기를 정의하는 Stages. (코드를 컴파일하는 단계 후에 테스트를 실행하는 단계)</li>
</ul>

<p>Job은 러너에 의해 실행된다. 동시 러너가 충분한 경우, 동일한 단계의 여러 작업이 병렬로 실행된다.</p>

<p>한 단계의 모든 작업이 성공하면 파이프라인은 다음 단계로 넘어간다.</p>

<p>한 단계의 어떤 작업이 실패하면 다음 단계는 일반적으로 실행되지 않고 파이프라인이 일찍 종료된다.</p>

<p>일반적으로 파이프라인은 자동으로 실행되며 생성된 후에는 개입이 필요하지 않다.</p>

<p>일반적으로 파이프라인은 다음 4단계의 순서로 실행된다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">compile</code> 이라는 작업이 있는 build 단계</li>
  <li><code class="language-plaintext highlighter-rouge">test1</code> 및 <code class="language-plaintext highlighter-rouge">test2</code> 라는 두 개의 작업이 있는 <code class="language-plaintext highlighter-rouge">test</code> 단계</li>
  <li><code class="language-plaintext highlighter-rouge">deploy-to-stage</code> 라는 작업이 있는 <code class="language-plaintext highlighter-rouge">staging</code> 단계</li>
  <li><code class="language-plaintext highlighter-rouge">deploy-to-prod</code> 라는 작업이 있는 <code class="language-plaintext highlighter-rouge">production</code> 단계</li>
</ul>

<h2 id="파이프라인에-수동-상호작용-추가">파이프라인에 수동 상호작용 추가</h2>

<p><code class="language-plaintext highlighter-rouge">when:manual</code> 키워드를 사용하여 구성된 수동 작업을 사용하면 파이프라인에서 진행하기 전에 수동 상호작용을 요구할 수 있다.</p>

<p>파이프라인 그래프에서 바로 이 작업을 수행할 수 있다. 특정 Job을 실행하려면 재생 버튼을 누르기만 하면 된다.</p>

<h2 id="파이프라인-기간-계산-방법">파이프라인 기간 계산 방법</h2>

<p>각 Job은 Period 로 표시되며 다음으로 구성된다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Period#first</code> (job이 시작되었을 때)</li>
  <li><code class="language-plaintext highlighter-rouge">Period#last</code> (job이 끝났을 때)</li>
</ul>

<h2 id="cicd-jobs">CI/CD Jobs</h2>

<p>파이프라인 구성은 Jobs로 시작된다. Job은 .gitlab-ci.yml 파일의 가장 기본적인 요소이다.</p>

<ul>
  <li>어떤 조건에서 실행되어야 할 지 명시하는 제약 조건으로 정의됨</li>
  <li>임의의 이름을 가진 최상위 요소이며 최서한 script 절을 포함함</li>
  <li>정의할 수 있는 수에는 제한이 없다</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>job1:
	script: <span class="s2">"execute-script-for-job1"</span>

job2:
	script: <span class="s2">"execute-script-for-job2"</span>
</code></pre></div></div>

<p>각 Job이 서로 다른 명령을 실행하는 두 개의 개별 Job이 있는 가장 간단한 CI/CD 구성이다.</p>

<p>Job은 러너에 의해 선택되고 러너 환경 내에서 실행된다. 각 Job이 독립적으로 실행되는 것이 중요하다.</p>

<h1 id="cicd-schedules">CI/CD Schedules</h1>

<p>프로젝트의 파이프라인을 예약하려면</p>

<ol>
  <li>프로젝트의 CI/CD &gt; Schedules 페이지로 이동한다.</li>
  <li>New schedule 버튼을 클릭한다.</li>
  <li>Schedule a new pipeline 양식을 채운다.</li>
  <li>Save pipeline schedule 버튼을 클릭한다.</li>
</ol>

<h2 id="only-및-except-사용">Only 및 Except 사용</h2>

<p>파이프라인이 예약된 경우에만 실행되도록 Job을 구성하려면 구성 키워드 only 및 except를 사용한다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>job:on-schedule:
  only:
    - schedules
  script:
    - make world

job:
  except:
    - schedules
  script:
    - make build
</code></pre></div></div>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="MLOps" /><summary type="html"><![CDATA[Gitlab]]></summary></entry><entry><title type="html">MLflow</title><link href="http://localhost:4000/mlops/mlflow/" rel="alternate" type="text/html" title="MLflow" /><published>2022-11-06T00:00:00+09:00</published><updated>2022-11-06T00:00:00+09:00</updated><id>http://localhost:4000/mlops/mlflow</id><content type="html" xml:base="http://localhost:4000/mlops/mlflow/"><![CDATA[<h1 id="mlflow">MLflow</h1>

<h2 id="mlflow란">MLflow란?</h2>
<p>MLflow는 머신러닝 모델의 실험을 tracking하고 model을 공유 및 deploy를 할 수 있도록 지원하는 라이브러리이다. 머신러닝 학습과 관련된 전반적인 lifecycle을 지원해주는 라이브러리이다.</p>

<p>MLflow는 Tracking, Projects, Models, Model Registry의 4가지 구성요소로 이루어져 있다. 모든 머신러닝 라이브러리에서 작동하고, 규칙에 따라 코드에 대한 대부분의 사항을 결정하고 기존 코드 베이스에 통합하기 위해 최소한의 변경만 하도록 설계되었다.</p>

<p>머신러닝 workflow의 어려운 점들을 살펴보면 다음과 같다.</p>

<ul>
  <li>실험 추적하기 어렵다.</li>
  <li>코드를 재현하기 어렵다.</li>
  <li>모델을 패키징하고 배포하는 표준 방법이 없다.</li>
  <li>모델(버전 및 단계 전환)을 관리 할 중앙 저장소가 없다.</li>
</ul>

<h2 id="mlflow-구성요소">MLflow 구성요소</h2>

<p><img width="706" alt="image" src="https://user-images.githubusercontent.com/63439911/200175937-dfeafcd0-ebaa-46d0-aa5b-41190c77f9ed.png" /></p>

<h3 id="1-mlflow-tracking">1. MLflow Tracking</h3>

<p>실험 기록을 추적하며 파라미터와 그 결과를 비교합니다.</p>

<h3 id="2-mlflow-projects">2. MLflow Projects</h3>

<p>ML code를 재사용, 재구현 가능한 형태로 패키징하여 다른 사람들과 공유하거나 프로덕션으로 변환한다.</p>

<h3 id="3-models">3. Models</h3>

<p>다양한 ML 라이브러리로 만들어진 모델을 관리하고 다양한 모델 서빙과 추론 플랫폼으로 배포한다.</p>

<h3 id="4-registry">4. Registry</h3>

<p>중앙 모델 스토어를 제공함으로써, 한 MLflow 모델의 전체 라이프 사이클을 협동적으로 관리한다. 이러한 관리 작업에는 모델 버전관리, 모델 스테이지 관리, 주석 처리 등을 포함한다.</p>

<h2 id="tracking">Tracking</h2>

<p>모델 학습 세션에 대한 메타데이터(log, hyperparmeter 정보, loss 변화, 모델 성능 등)를 관리하는 중앙화된 레포지토리를 제공하는 기능이다.</p>

<p>MLflow Tracking에는 두 가지 backend store가 있고 다음과 같은 특징을 가집니다.</p>

<ol>
  <li>Entity store : 학습과 관련된 가벼운 메타데이터를 수집하고 통합한다. Metric, Parameter, Source 및 버전 정보를 포함한다.
    <ol>
      <li>file store : 유닉스 및 윈도우 파일 시스템과 호환됨</li>
      <li>SQL store : SQLAlchemy를 사용하여 대부분의 DB와 연동이 가능하다.</li>
      <li>REST store : 자체적인 인프라를 구축하고 싶은 조직에게 restful한 추상화를 제공한다. 기존의 시스템과 효과적으로 결합이 가능하다.</li>
    </ol>
  </li>
  <li>Artifact Store : 메타데이터와 다르게 상대적으로 무거운 데이터를 저장한다. 학습데이터, 모델파일이 이에 해당합니다.
    <ol>
      <li>Amazon S3 backend Store</li>
      <li>GCP</li>
    </ol>
  </li>
</ol>

<h2 id="project">Project</h2>

<p>모델의 재생산성, 재사용성을 확보하기 위한 기능을 제공한다.</p>

<ol>
  <li>재생산가능한 ML 실행을 위한 패키징 포맷
    <ol>
      <li>어떤 코드 폴더든 git repository든 지원한다.</li>
      <li>Project Config를 포함한 optional ML project file을 관리할 수 있다.</li>
    </ol>
  </li>
  <li>재생산성을 위해 dependency 정의
    <ol>
      <li>Conda/R/docker dependency에 대한 정보를 ML 프로젝트에 명시적으로 기록할 수 있다.</li>
      <li>거의 모든 환경에서 재생산 가능하도록 지원한다.</li>
    </ol>
  </li>
  <li>프로젝트 구동을 위한 실행 API
    <ol>
      <li>CLI/Python/Java</li>
      <li>로컬 및 원격 실행을 지원한다.</li>
    </ol>
  </li>
</ol>

<h2 id="mlflow-models">MLflow Models</h2>

<p>모델이 학습을 다 한 이후에는 정해진 양식에 따른 입력을 받았을 때 추론 결과를 낼 수 있도록 배포를 해야한다. 이를 위해 MLflow는 다양한 환경(Docker, Spark, K8s) 다양한 툴 (TF, Pytorch, Scikit-Learn) 로 모델 배포를 할 수 있도록 중간 역할을 해준다.</p>

<p><img src="https://user-images.githubusercontent.com/63439911/200175957-5884dd03-cb06-4d64-82a6-b8f1c47d3d5a.png" alt="image" /></p>

<ul>
  <li>ML 모델을 위한 패키징 포맷 제공 : ML 모델 파일이 있는 어떤 디렉토리든 사용 가능하다.</li>
  <li>재생산성을 위해 dependency 정의 : ML 모델의 config에 conda 환경 등의 dependency에 대한 정보를 제공할 수 있다.</li>
  <li>모델 생성 유틸리티 : 어떤 프레임워크에서 나온 모델이든 MLflow 포맷으로 저장해준다.</li>
  <li>배포 API : CLI/Python/R/Java 등의 배포 API를 제공한다.</li>
</ul>

<h2 id="mlflow-registry">Mlflow Registry</h2>

<p>ML 모델을 개발하다보면 하이퍼파라미터, 모델의 구조든 다양한 변화를 가한 버전이 생긴다. 이러한 다양한 버전, 스테이지를 충돌 없이 쉽게 관리할 수 있는 기능을 제공한다.</p>

<p><img src="https://user-images.githubusercontent.com/63439911/200175965-1ada89da-e52b-4477-a75b-1139fcaf9a95.png" alt="image" /></p>

<ul>
  <li>중앙화된 레포지토리 : 이 레포지토리는 모든 등록된 모델들과 그에 상응하는 메타데이터를 포함하고 있다. 등록된 모델들의 모든 기존 버전들은 여기에 저장되고 접근이 가능하다.</li>
  <li>모델 Staging : 등록된 모델들은 미리 정의되거나 혹은 커스텀 스테이지에 할당되어 ML lifecycle 내에서 어떤 phase에 있는지를 나타낼 수 있다. 이를 통해 개발자들은 프로덕션 모델에 영향을 미치지 않은 채로 한 모델의 새로운 버전을 개발 스테이지로 배포할 수 있게 해준다.</li>
  <li>변화 관리와 모니터링 : 사용자들은 모델 레지스트리에 변경사항이 발생했을 때 핵심 정보를 로그로 남길 수 있도록 이벤트를 설계할 수 있다.</li>
</ul>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="MLOps" /><summary type="html"><![CDATA[MLflow]]></summary></entry><entry><title type="html">MLOps</title><link href="http://localhost:4000/mlops/mlops/" rel="alternate" type="text/html" title="MLOps" /><published>2022-10-24T00:00:00+09:00</published><updated>2022-10-24T00:00:00+09:00</updated><id>http://localhost:4000/mlops/mlops</id><content type="html" xml:base="http://localhost:4000/mlops/mlops/"><![CDATA[<h2 id="sagemaker">SageMaker</h2>
<p><img src="https://user-images.githubusercontent.com/63439911/198020774-94203ef7-ec61-4c7d-98e0-4fc7e62dd142.png" alt="image" />
EC2 인스턴스 위에 설치한 완전 관리형 서비스이다. EC2 인스턴스 위에 Jupyter Notebook을 설치한 것</p>

<h3 id="장점">장점</h3>

<ul>
  <li>클라우드 환경이라 고성능 컴퓨터가 필요없음</li>
  <li>ML 패키지 설치가 필요없음</li>
  <li>코드 작성부터 배포까지 한 번에 가능</li>
</ul>

<h2 id="bentoml">BentoML</h2>

<h3 id="serving">Serving</h3>

<p>개발된 모델을 서빙 하는 것이다.</p>

<p>크게 <code class="language-plaintext highlighter-rouge">Batch,</code> <code class="language-plaintext highlighter-rouge">Online,</code> <code class="language-plaintext highlighter-rouge">Edge(Mobile)</code> 로 나눠져있다. Serving 시에 의존성 관리를 중요하게 생각하기 때문에 Docker나 Kubernetes를 기반으로 한다.</p>

<ul>
  <li>Batch Serving : 특정 주기로 서빙하는 것
    <ul>
      <li>Batch로 한꺼번에 많은 양을 처리함</li>
      <li>Airflow나 Cronjob을 특정 주기 시간단위로 예측한다.</li>
      <li>예측 결과를 DB에 저장하고 서버에서 활용한다.</li>
    </ul>
  </li>
  <li>Online Serving : API 서빙, 실시간 요청에 따른 반응을 함
    <ul>
      <li>동시에 여러 요청에 대한 확장대책이 필요하고 Batch 처리가 불가능</li>
      <li>Kfserving, BentoML, Tensorflow Serving, Seldon Core 등의 라이브러리가 있다.</li>
    </ul>
  </li>
</ul>

<h3 id="bentoml-1">BentoML</h3>
<p><img src="https://user-images.githubusercontent.com/63439911/198021167-60d6e1db-df00-489f-a8c9-e7ec4175144e.png" alt="image" />
적은 코드로 production 서비스까지 가능하다. 모델 관리를 위한 웹 대시보드 또한 존재한다.</p>

<p>Python Script로 작성해서 Airflow로 접근이 가능하다.</p>

<ul>
  <li>
    <p>장점</p>

    <p>API 서버를 자동으로 만들어준다.</p>

    <p>모델 저장소와 배포 관리를 위한 웹 대시보드, swagger 제공</p>
  </li>
  <li>
    <p>Adaptive Micro Batching</p>

    <p>모델 서빙시 개별 추론 요청을 배치단위로 처리하는 것은 성능에 큰 영향을 준다.</p>

    <p>BentoML은 HTTP 처리 데이터 처리과정까지 Micro batching을 지원한다.</p>
  </li>
</ul>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="MLOps" /><summary type="html"><![CDATA[SageMaker EC2 인스턴스 위에 설치한 완전 관리형 서비스이다. EC2 인스턴스 위에 Jupyter Notebook을 설치한 것]]></summary></entry><entry><title type="html">Kubernetes - 기본명령어</title><link href="http://localhost:4000/devops/kubernetes/" rel="alternate" type="text/html" title="Kubernetes - 기본명령어" /><published>2022-10-23T00:00:00+09:00</published><updated>2022-10-23T00:00:00+09:00</updated><id>http://localhost:4000/devops/kubernetes</id><content type="html" xml:base="http://localhost:4000/devops/kubernetes/"><![CDATA[<h2 id="kubectl-명령어">Kubectl 명령어</h2>

<table>
  <thead>
    <tr>
      <th>명령어</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>apply</td>
      <td>원하는 상태를 적용한다. 보통 -f 옵션으로 파일과 함께 사용한다.</td>
    </tr>
    <tr>
      <td>get</td>
      <td>리소스 목록을 보여준다.</td>
    </tr>
    <tr>
      <td>describe</td>
      <td>리소스의 상태를 자세하게 보여준다.</td>
    </tr>
    <tr>
      <td>delete</td>
      <td>리소스를 제거한다.</td>
    </tr>
    <tr>
      <td>logs</td>
      <td>컨테이너의 로그를 본다.</td>
    </tr>
    <tr>
      <td>exec</td>
      <td>컨테이너에 명령어를 전달한다. 컨테이너에 주로 접근할 때 사용한다.</td>
    </tr>
    <tr>
      <td>config</td>
      <td>kubectl 설정을 관리한다.</td>
    </tr>
  </tbody>
</table>

<h2 id="리소스-목록보기-get">리소스 목록보기 (get)</h2>

<p>출력 형태를 변경할 수 있는 <code class="language-plaintext highlighter-rouge">-o</code> 와 레이블을 확인할 수 있는 <code class="language-plaintext highlighter-rouge">—show-lables</code>가 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># pod 조회</span>
kubectl get pod

<span class="c"># 여러 개 조회 가능</span>
kubectl get pods
kubectl get po

<span class="c"># 여러 type 선택 가능</span>
kubectl get pod,service
<span class="c"># 줄임말 가능</span>
kubectl get po,svc

<span class="c"># pod, replicaset, deployment, service, job 조회 =&gt; all</span>
kubectl get all

<span class="c"># 결과 포맷 변경</span>
kubectl get pod <span class="nt">-o</span> wide
kubectl get pod <span class="nt">-o</span> yaml
kubectl get pod <span class="nt">-o</span> json

<span class="c"># label 조회</span>
kubectl get pod <span class="nt">--show-labels</span>
</code></pre></div></div>

<h2 id="리소스-상태-보기-describe">리소스 상태 보기 (describe)</h2>

<p>describe 명령어를 통해 해당 리소스의 상세한 정보를 볼 수 있다. 쿠버네티스를 운영하면서 가장 많이 확인하는 부분은 <code class="language-plaintext highlighter-rouge">events</code> 이다. 현재 pod의 상태를 이벤트 별로 확인할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># pod 조회로 이름 검색</span>
kubectl get pod

<span class="c"># 조회한 이름으로 상세 확인</span>
kubectl describe pod/[name] 
</code></pre></div></div>

<h2 id="컨테이너-로그-조회-logs">컨테이너 로그 조회 (logs)</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 특정 pod 로그 조회</span>
kubectl logs <span class="o">[</span>pod_name]

<span class="c"># 실시간 로그 보기</span>
kubectl logs <span class="nt">-f</span> <span class="o">[</span>pod_name]
</code></pre></div></div>

<h2 id="컨테이너-명령-전달-exec">컨테이너 명령 전달 (exec)</h2>

<p>shell로 접속하여 컨테이너 상태를 확인하는 경우에 <code class="language-plaintext highlighter-rouge">-it</code> 옵션을 사용하고 여러 개의 컨테이너가 있는 경우에는 <code class="language-plaintext highlighter-rouge">-c</code> 옵션으로 컨테이너를 지정한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="o">[</span>pod_name] <span class="nt">--</span> <span class="o">[</span><span class="nb">command</span><span class="o">]</span>
</code></pre></div></div>

<h2 id="설정-관리-config">설정 관리 (config)</h2>

<p>kubectl은 여러 개의 쿠버네티스 클러스터를 context로 설정하고 필요에 따라 선택할 수 있다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 현재 컨텍스트 확인
kubectl config current-context

# 컨텍스트 설정
kubectl config use-context minikube
</code></pre></div></div>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="DevOps" /><summary type="html"><![CDATA[Kubectl 명령어]]></summary></entry><entry><title type="html">Linux</title><link href="http://localhost:4000/language/linux/" rel="alternate" type="text/html" title="Linux" /><published>2022-10-22T00:00:00+09:00</published><updated>2022-10-22T00:00:00+09:00</updated><id>http://localhost:4000/language/linux</id><content type="html" xml:base="http://localhost:4000/language/linux/"><![CDATA[<h2 id="리눅스-기본-명령어-정리">리눅스 기본 명령어 정리</h2>

<h2 id="ls">ls</h2>
<p>디렉토리 내 파일 목록 나열</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ls  -&gt; 현재 디렉토리 파일 목록
ls /etc/sysconfig    -&gt; /etc/sysconfig 아래 디렉토리 조회
ls -a   -&gt; 숨김 파일 포함 목록 조회
ls -l   -&gt; 자세히 보기
ls *.exe    -&gt; 확장자가 exe인 목록 보여줌
ls -l /etc/sysconfig/a* -&gt; /etc/sysconfig/ 디렉토리 안에 a로 시작하는 목록 자세히 조회
</code></pre></div></div>

<h2 id="cd">cd</h2>
<p>디렉토리 이동</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd  -&gt; 사용자의 홈 디렉토리로 이동
cd~centos   -&gt; centos 사용자의 홈 디렉토리로 이동
cd ..   -&gt; 하위 디렉토리로 이동
cd /etc/sysconfig   -&gt; 절대 경로 이동
cd ../etc/sysconfig -&gt; 상대 경로 이동 (현재 디렉토리의 상위로 이동한 뒤에 다시 /etc/sysconfig 로 이동)
</code></pre></div></div>

<h2 id="pwd">pwd</h2>
<p>print working directory, 현재 디렉토리의 전체경로를 print</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pwd -&gt; 현재 작업중인 디렉토리 경로 출력
</code></pre></div></div>

<h2 id="rm">rm</h2>
<p>파일, 디렉토리 삭제</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rm test.txt -&gt; test.txt 파일 삭제 (내부적으로 rm -i와 연결되어 동작)
rm -i test.txt  -&gt; 삭제 확인 후 삭제
rm -f test.txt  -&gt; 강제로 바로 삭제
rm -r abc   -&gt; 디렉토리 삭제
rm -rf abc  -&gt; 디렉토리 하위에 있는 것 전부 삭제
</code></pre></div></div>

<h2 id="cp">cp</h2>
<p>파일, 디렉토리 복사</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cp a.txt b.txt  -&gt; a.txt를 b.txt라는 이름으로 바꿔서 복사
cp -r b a   -&gt; b라는 디렉토리를 a라는 디렉토리에 복사
</code></pre></div></div>

<h2 id="touch">touch</h2>
<p>파일크기가 0인 파일 생성, 이미 존재한다면 마지막 수정시간 변경</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>touch test.txt
</code></pre></div></div>

<h2 id="mv">mv</h2>
<p>파일이나 디렉토리 이름을 변경하거나 다른 디렉토리로 옮길 때 사용</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mv test.txt/etc/sysconfig   -&gt; test.txt를 /etc/sysconfig로 이동
mv a b c x  -&gt; a와 b,c 파일 /x 디렉토리로 이동
mv test.txt practice.txt    -&gt; test.txt를 practice.txt로 변경하여 이동
</code></pre></div></div>

<h2 id="mkdir">mkdir</h2>
<p>디렉토리 생성</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir abc   -&gt; abc라는 디렉토리 생성
mkdir -p /parent/child  -&gt; 부모 디렉토리 아래 자식 디렉토리 생성, 부모 디렉토리가 없다면 둘 다 함께 생성
</code></pre></div></div>

<h2 id="rmdir">rmdir</h2>
<p>비어있는 디렉토리 삭제</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rmdir abc
</code></pre></div></div>

<h2 id="cat">cat</h2>
<p>파일 내용 출력 여러개를 붙여서 나열 가능</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat a.txt b.txt
</code></pre></div></div>

<h2 id="head">head</h2>
<p>파일의 앞 10행 화면 출력, 출력 행 수 지정 가능</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head anaconda-ks.cfg
head -5 anaconda-ks.cfg
</code></pre></div></div>

<h2 id="tail">tail</h2>
<p>파일의 뒤 10행 화면 출력, 출력 행 수 지정 가능</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tail anaconda-ks.cfg
tail -5 anaconda-ks.cfg
</code></pre></div></div>

<h2 id="more">more</h2>
<p>텍스트 형식의 파일을 페이지 단위로 출력한다.<br />
space를 누르면 다음 페이지<br />
b를 누르면 앞페이지로 이동<br />
q를 누르면 종료</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>more anaconda-ks.cfg
more +100 anaconda-ks.cfg   -&gt; 100행부터 출력
</code></pre></div></div>

<h2 id="less">less</h2>
<p>more에 pgUp pgDn 기능 추가</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>anaconda-ks.cfg
less +100 anaconda-ks.cfg   -&gt; 100gㅐㅇ부터 출력
</code></pre></div></div>

<h2 id="file">file</h2>
<p>해당파일이 어떤 파일인지 표시한다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>file test.txt
file /user/bin/gzip
</code></pre></div></div>

<h2 id="clear">clear</h2>
<p>터미널 화면 지우기</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clear
</code></pre></div></div>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="Language" /><summary type="html"><![CDATA[리눅스 기본 명령어 정리]]></summary></entry><entry><title type="html">Kubernetes - GPU</title><link href="http://localhost:4000/devops/kubernetes-gpu/" rel="alternate" type="text/html" title="Kubernetes - GPU" /><published>2022-10-19T00:00:00+09:00</published><updated>2022-10-19T00:00:00+09:00</updated><id>http://localhost:4000/devops/kubernetes-gpu</id><content type="html" xml:base="http://localhost:4000/devops/kubernetes-gpu/"><![CDATA[<h1 id="kubernetes---gpu">Kubernetes - GPU</h1>

<p><img src="https://user-images.githubusercontent.com/63439911/196692537-322e934e-4d39-4466-9fd6-27f3b73dd105.png" alt="image" /></p>

<h2 id="cpu란">CPU란?</h2>

<p>CPU는 컴퓨터 및 운영 체제에 필요한 명령과 처리를 실행한다. 또한 웹 서핑에서 스프레드시트 제작에 이르는 프로그램의 실행 속도를 결정하는 데에 중요하게 작용한다.</p>

<p>CPU는 다양한 워크로드, 특히 대기 시간이나 코어당 성능이 중요한 워크로드에 적합하다. 코어 수가 적으며 개별적인 작업과 신속한 작업 처리에 이러한 코어를 집중한다. CPU가 일을 할 때 한 개씩, 순차적으로 처리하는데 이것을 <strong>직렬 처리</strong>방식이라고 한다. 이 때문에 연속적인 컴퓨팅이나 db 실행과 같은 작업에 적합하다.</p>

<table>
  <tbody>
    <tr>
      <td>핵심 기능 3단계</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>데이터 가져오기(Fetch)
    <ul>
      <li>데이터는 이진수로 표시되며 RAM에서 CPU로 전달된다.</li>
      <li>각 실행 작업은 모든 작업의 일부분이므로 CPU는 다음 작업이 뭔지 알아야하는데 이것을 PC에 보관한다.</li>
    </ul>
  </li>
  <li>디코딩
    <ul>
      <li>명령을 가져와서 IR에 저장하면 CPU는 명령 해독기라는 회로로 명령을 전달한다.</li>
      <li>명령어는 CPU의 다른 부분으로 전달하여 작동을 위해 전달되는 신호로 변환된다.</li>
    </ul>
  </li>
  <li>실행
    <ul>
      <li>디코딩된 명령문은 완료될 CPU의 관련 부분으로 전송된다.</li>
      <li>결과는 대개 CPU 레지스터에 기록되며 이후 명령문에 의해 참조 될 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="gpu란">GPU란?</h2>

<p>GPU는 그래픽 처리나 3D 모델링을 위한 프로세서이다.</p>

<p>예전에는 3D 그래픽을 주로 CPU로 구현했으나 더 빠르고 실시간 그래픽 처리가 필요해짐에 따라 GPU가 나오게 되었다.</p>

<p>CPU의 연산을 담당하는 연산장치(ALU)는 구조가 매우 복잡하고 각종 제어 처리를 담당한다.</p>

<p>그에 비해 GPU는 연산장치(ALU)의 구조가 단순하고 작은 제어/캐시 영역을 가진다. 또한 다수의 코어로 이루어져 있다.</p>

<p>이런 구조적인 특징으로 인해 여러 개의 코어를 동시에 병렬로 작동시켜 단순 계산을 빠르게 할 수 있다.</p>

<h2 id="k8s에서의-gpu">K8s에서의 GPU</h2>

<h3 id="디바이스-플러그인">디바이스 플러그인</h3>

<p>쿠버네티스는 디바이스 플러그인을 구현하여 파드가 GPU와 같이 특별한 하드웨어 기능에 접근할 수 있게 한다.</p>

<p>AMD 혹은 NVDIA 디바이스 플러그인을 사용하여 쿠버네티스는 GPU를 스케쥴 가능한 리소스로써 노출시킨다.</p>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="DevOps" /><summary type="html"><![CDATA[Kubernetes - GPU]]></summary></entry><entry><title type="html">Kubernetes - 구성요소</title><link href="http://localhost:4000/devops/kubernetes-components/" rel="alternate" type="text/html" title="Kubernetes - 구성요소" /><published>2022-10-18T00:00:00+09:00</published><updated>2022-10-18T00:00:00+09:00</updated><id>http://localhost:4000/devops/kubernetes-components</id><content type="html" xml:base="http://localhost:4000/devops/kubernetes-components/"><![CDATA[<h2 id="k8s-컴포넌트">K8s 컴포넌트</h2>

<p>쿠버네티스를 배포하면 클러스터를 얻는다. 쿠버네티스 클러스터는 컨테이너화된 애플리케이션을 실행하는 노드라고 하는 워커 머신의 집합이다.
<span style="color: red">쿠버네티스의 컴포넌트는 크게 쿠버네티스의 기능 제어를 담당하는 컨트롤 플레인과 컴포넌트와 컨트롤 플레인 컴포넌트의 요청을 받아 각 노드에서 동작을 담당하는 노드 컴포넌트로 나누어 볼 수 있다.</span></p>

<blockquote>
  <p>노드</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>쿠버네티스의 작업 장비
</code></pre></div></div>

<p>워커 노드는 애플리케이션의 구성요소인 파드를  호스트한다.</p>

<blockquote>
  <p>파드</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>클러스터에서 실행중인 컨테이너의 집합
</code></pre></div></div>

<p>컨트롤 플레인은 워커 노드와 클러스터 내 파드를 관리한다.</p>

<blockquote>
  <p>컨트롤 플레인</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어이다.
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/63439911/196174687-0d812161-41ea-45fc-9e0a-273454abff03.png" alt="쿠버네티스 구성요소" /></p>

<p>쿠버네티스 클러스터 구성 요소</p>

<h2 id="쿠버네티스-클러스터란">쿠버네티스 클러스터란?</h2>

<p>컨테이너 형태의 어플리케이션을 호스팅하는 물리/가상 환경의 노드들로 이루어진 집합이다.</p>

<p>쿠버네티스는 호스트 환경에 구성도니 자원들을 클러스터 단위로 추상화해서 관리한다.</p>

<p>하나의 클러스터 안에는 클러스터 내부 요소들을 제어하는 <code class="language-plaintext highlighter-rouge">컨트롤 플레인 역할</code>을 수행할 <code class="language-plaintext highlighter-rouge">마스터 노드</code>를 두고 관리자는 이 마스터 노드를 통해 클러스터 전체를 제어하는 구성을 따른다.</p>

<p>쿠버네티스 클러스터는 용도에 따라 크게 <code class="language-plaintext highlighter-rouge">워커 노드</code>와 <code class="language-plaintext highlighter-rouge">마스터 노드</code>로 구분된다.</p>

<ul>
  <li>워커 노드 : 각기 다른 목적과 기능으로 세분화된 컨테이너들이 실제 배치되는 노드이다.</li>
  <li>마스터 노드 : 컨테이너 선단을 지휘하는 통제역할을 한다. 대규모 컨테이너를 운영하려면 각 워커 노드들의 가용 리소스 현황을 고려하여 최적의 컨테이너 배치와 모니터링, 그리고 각 컨테이너에 대한 효율적인 추적 관리가 필요하다. 이러한 역할을 수행한다.</li>
</ul>

<h2 id="쿠버네티스-클러스터의-내부-구조">쿠버네티스 클러스터의 내부 구조</h2>

<p>쿠버네티스에서 클러스터들의 모든 구성 요소는 오직 API 서버를 통해서만 접근이 가능하다.
<img src="https://user-images.githubusercontent.com/63439911/197381920-d2d64192-4960-4f81-9619-efc682e790b8.png" alt="image" />
<code class="language-plaintext highlighter-rouge">Kubernetes Master</code>는 마스터 노드에 포함된 <code class="language-plaintext highlighter-rouge">컨트롤 플레인</code>에 해당한다.</p>

<p>컨트롤플레인은 클러스터 전체의 workload resource 등 주요 구성 요소들을 배포하고 제어하는 역할을 한다.</p>

<h2 id="컨트롤-플레인-컴포넌트">컨트롤 플레인 컴포넌트</h2>

<p>클러스터에 관한 전반적인 결정을 수행하고 클러스터 이벤트를 감지하고 반응한다.</p>

<p>클러스터 내 어떠한 머신에서든 동작할 수 있다. 그러나 간결성을 위해 구성 스크립트는 보통 동일 머신 상에 모든 컨트롤 플레인 컴포넌트를 구동시키고 사용자 컨테이너는 해당 머신 상에 동작시키지 않는다.</p>

<blockquote>
  <p>kube-apiserver</p>
</blockquote>

<p>API 서버는 쿠버네티스 API를 노출하는 쿠버네티스 컨트롤 플레인 컴포넌트이다. API 서버는 쿠버네티스 컨트롤 플레인의 프론트 엔드이다. kube-apiserver는 수평을 확장되도록 디자인되어서 더 많은 인스턴스를 배포해서 확장할 수 있다. 여러 인스턴스를 실행하고 그것들 간의 트래픽을 균형있게 조절할 수 있다.</p>

<blockquote>
  <p>etcd</p>
</blockquote>

<p>모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성,고가용성 키-값 저장소이다.</p>

<p>쿠버네티스 클러스터에서 etcd를 뒷단의 저장소로 사용한다면 이 데이터는 반드시 백업해야한다.</p>

<blockquote>
  <p>kube-scheduler</p>
</blockquote>

<p>클러스터는 여러 노드로 구성되어 있고 기본적인 작업의 단위인 파드는 여러 노드 중 특정 노드에 배치되어 동작하게 된다. 이 때 새로 새성된 파드를 감지하여 어떤 노드로 배치할지 결정하는 작업을 스케줄링이라고 한다. 이 스케줄링을 담당하는 컴포넌트가 kube-scheduler이다.</p>

<blockquote>
  <p>kube-controller-manager</p>
</blockquote>

<p>컨트롤러 프로세스를 실행하는 컨트롤 플레인 컴포넌트이다. 각 컨트롤러는 분리된 프로세스이지만 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다.</p>

<blockquote>
  <p>Cloud-Controller-Manager</p>
</blockquote>

<p>클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트이다. 클라우드 컨트롤러 매니저를 통해 클러스터를 클라우드 공급자의 API에 연결하고, 해당 클라우드 플랫폼과 상호 작용하는 컴포넌트와 클러스터와만 상호 작용하는 컴포넌트를 구분할 수 있게 해준다.</p>

<p>클라우드 제공자 전용 컨트롤러만 실행한다.</p>

<p>kube-controller-manager와 마찬가지로 논리적으로 독립적인 여러 컨트롤 루프를 단일 프로세스로 실행하는 단일 바이너리로 결합한다. 수평으로 확장해서 성능을 향상시키거나 장애를 견딜 수 있다.</p>

<ul>
  <li>노드 컨트롤러 : 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것</li>
  <li>라우트 컨트롤러 : 기본 클라우드 인프라에 경로를 구성하는 것</li>
  <li>서비스 컨트롤러 : 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것</li>
</ul>

<h2 id="노드-컴포넌트">노드 컴포넌트</h2>

<p>동작중인 파드를 유지시키고 쿠버네티스 런타임 환경을 제공하며, 모든 노드 상에서 동작한다.</p>

<blockquote>
  <p>Kubelet</p>
</blockquote>

<p>클러스터의 각 노드에서 실행되는 에이전트로 파드에서 컨테이너가 확실하게 동작하도록 관리한다.</p>

<p>쿠버네티스를 토앻 생성되지 않는 컨테이너는 관리하지 않는다.</p>

<blockquote>
  <p>Kube-proxy</p>
</blockquote>

<p>클러스터의 각 노드에서 실행되는 네트워크 프록시로, 쿠버네티스의 서비스 개념의 구현부이다.</p>

<p>노드의 규칙을 관리한다.</p>

<p>운영 체제에 가용한 패킷 필터층 계층이 있는 경우엔 이것을 사용하고 아니면 트래픽 자체를 forward한다.</p>

<blockquote>
  <p>컨테이너 런타임</p>
</blockquote>

<p>컨테이너 런타임은 컨테이너 실행을 담당하는 소프트웨어이다.</p>

<h2 id="에드온">에드온</h2>

<p>쿠버네티스 리소스(데몬셋, 디플로이먼트 등)를 이용하여 클러스터 기능을 구현한다. 이들은 클러스터 단위의 기능을 제공하기 때문에 에드온에 대한 네임스페이스 리소스는 kube-system 네임스페이스에 속한다.</p>

<h2 id="dns">DNS</h2>

<p>절대적으로 요구하지는 않지만 많은 예시에서 필요로 하기 때문에 쿠버네티스 클러스터는 클러스터 DNS를 갖추어야만 한다.</p>

<p>클러스터 DNS는 구성환경 내 다른 DNS 서버와 더불어, 쿠버네티스 서비스를 위해 DNS 레코드를 제공해주는 DNS 서버이다.</p>

<h2 id="웹-ui-대시보드">웹 UI (대시보드)</h2>

<p>대시보드는 쿠버네티스의 클러스터에서 동작하는 애플리케이션에 대한 관리와 문제 해결을 할 수 있도록 해준다.</p>

<h2 id="컨테이너-리소스-모니터링">컨테이너 리소스 모니터링</h2>

<p>컨테이너 리소스 모니터링은 중앙 데이터베이스 내의 컨테이너들에 대한 포괄적인 시계열 매트릭스를 기록하고 그 데이터를 열람하기 위한 UI를 제공해 준다.</p>

<h2 id="클러스터-레벨-로깅">클러스터-레벨 로깅</h2>

<p>검색/열람 인터페이스와 함께 중앙 로그 저장소에 컨테이너 로그를 저장하는 책임을 진다.</p>

<h2 id="쿠버네티스-api">쿠버네티스 API</h2>

<p>쿠버네티스 컨트롤 플레인의 핵심은 API 서버이다. API 서버는 최종 사용자, 클러스터의 다른 부분 그리고 외부 컴포넌트가 서로 통신할 수 있도록 HTTP API를 제공한다.</p>

<blockquote>
  <p>컨트롤 플레인</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어이다.
</code></pre></div></div>

<p>쿠버네티스 API를 사용하면 쿠버네티스의 API 오브젝트, 네임스페이스 컨피그맵 그리고 이벤트를 질의하고 조작할 수 있다.</p>

<h2 id="파드">파드</h2>
<p><img width="381" alt="image" src="https://user-images.githubusercontent.com/63439911/197164930-5157b0ed-34b8-4895-96fc-68091fdc2ce5.png" />
파드는 쿠버네티스의 가장 기본적인 배포 단위이다.</p>

<p>마스터 노드에서 워크노드로 pod를 전달하고, 워커노드에서는 pod를 수행하는 구조이다. 그렇기 때문에 한 개의 워커노드에는 N개의 pod가 들어가게 된다.</p>

<p>쿠버네티스는 컨테이너를 개별적으로 배포하는 것이 아니라 Pod 안에 컨테이너를 탑재하여 배포한다.</p>

<p>Pod 안에는 1개 이상의 컨테이너가 탑재될 수 있다. (<span style="color: blue">1pod = N containers</span>)</p>

<p>여러 컨테이너를 pod 단위로 묶어서 배포하는 이유는 다음과 같다.</p>

<ol>
  <li>Pod 내부 컨테이너 간의 IP 및 포트 공유를 통한 통신 용이성 향상
    <ul>
      <li>두 컨테이너 A,B가 한 개의 pod에 탑재될 경우 두 컨테이너 끼리는 실시간으로 데이터를 교환하며 그에 따라 상태를 업데이트해야한다. 이 때 두 컨테이너는 별도의 IP 호출없이 localhost를 통해 통신이 가능하다.</li>
    </ul>
  </li>
  <li>pod 내부 컨테이너 간의 디스크 볼륨 공유
    <ul>
      <li>pod 내에 함꼐 배포된 컨테이너끼리는 디스크 볼륨을 공유할 수 있기 때문에 서로의 파일을 읽어올 수 있다.</li>
      <li>또한 로그 수집기를 사이드카 패턴을 통해 pod에 탑재하여 배포할 경우 pod 내부 컨테이너들의 로그를 모두 수집할 수 있다.</li>
    </ul>
  </li>
</ol>

<p>만들어진 pod를 배포하면 단일 인스턴스가 만들어진다. 수평적으로 어플리케이션을 확장하기 위해서는 단일 인스턴스를 만드는 pod를 복제하는 레플리케이션을 수행해야 한다.</p>

<h2 id="pod-생성">Pod 생성</h2>

<p>pod는 주로 yaml, JSON 등의 template를 통해 생성한다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1 # api의 버전 
kind: Pod # 생성할 쿠버네티스 리소스 타입
metadata:
	name: myapp-pod
	labels: # 특정 쿠버네티스 리소스를 검색할 때 사용하는 Key-Value 형태의 데이터이다.
		app: myapp # myapp이라는 app label을 통해 myapp-pod를 검색할 수 있다.
spec: # pod의 구체적인 사양을 정의하는 부분
	containers:
	- name: myapp-container
		image: busybox # docker registry를 구체적으로 명시하여 가져올 수 있다.
		command: ['sh','-c','echo Hello Kubernetes! &amp;&amp; sleep 3600']
</code></pre></div></div>
<h2 id="deployment란">Deployment란?</h2>

<p>ReplicaSet을 이용하여 pod를 업데이트하고 이력을 관리하여 롤백하거나 특정 버전으로 돌아갈 수 있다.</p>

<p>Deployment는 새로운 이미지로 업데이트하기 위해 ReplicaSet을 이용한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: apps/v1
kind: Deployment <span class="c"># deployment</span>
metadata:
  name: echo-deploy
spec:
  replicas: 4
  selector:
    matchLabels:
      app: <span class="nb">echo
      </span>tier: app
  template:
    metadata:
      labels:
        app: <span class="nb">echo
        </span>tier: app
    spec:
      containers:
        - name: <span class="nb">echo
          </span>image: ghcr.io/subicura/echo:v1
</code></pre></div></div>

<p>버전을 업데이트하면 새로운 ReplicaSet을 생성하고 해당 ReplicaSet이 새로운 버전의 pod를 생성한다.</p>

<p>과정을 그림으로 다음과 같이 나타낼 수 있다.
<img src="https://user-images.githubusercontent.com/63439911/197397137-e71ff68e-1d00-4acb-984b-a7174e9c8b66.png" alt="image" /><img src="https://user-images.githubusercontent.com/63439911/197397150-b6adb45e-2a57-4b5e-b625-46fa5878bc26.png" alt="image" />
<img src="https://user-images.githubusercontent.com/63439911/197397160-ff433ce8-f14a-4368-b24e-3a02e5938146.png" alt="image" />
<img src="https://user-images.githubusercontent.com/63439911/197397168-c63b8149-2865-4614-bae9-855b2bd538f9.png" alt="image" />
<img src="https://user-images.githubusercontent.com/63439911/197397174-dfd5cd29-ff0e-4a4e-9359-c622ee05e9b4.png" alt="image" /></p>
<h3 id="버전-관리">버전 관리</h3>

<p>Deployment는 변경된 상태를 기록한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 히스토리 확인</span>
kubectl rollout <span class="nb">history </span>deploy/echo-deploy

<span class="c"># revision 1 히스토리 상세 확인</span>
kubectl rollout <span class="nb">history </span>deploy/echo-deploy <span class="nt">--revision</span><span class="o">=</span>1

<span class="c"># 바로 전으로 롤백</span>
kubectl rollout undo deploy/echo-deploy

<span class="c"># 특정 버전으로 롤백</span>
kubectl rollout undo deploy/echo-deploy <span class="nt">--to-revision</span><span class="o">=</span>2
</code></pre></div></div>

<h3 id="배포-전략-설정">배포 전략 설정</h3>

<p>RollingUpdate방식을 사용하여 동시에 업데이트하는 Pod의 개수를 변경하는 코드는 다음과 같다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-deploy-st
spec:
  replicas: 4
  selector:
    matchLabels:
      app: echo
      tier: app
  minReadySeconds: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 3
      maxUnavailable: 3
  template:
    metadata:
      labels:
        app: echo
        tier: app
    spec:
      containers:
        - name: echo
          image: ghcr.io/subicura/echo:v1
          livenessProbe:
            httpGet:
              path: /
              port: 3000
</code></pre></div></div>
<h2 id="namespace란">namespace란?</h2>
<p><img src="https://user-images.githubusercontent.com/63439911/197184866-a8091438-13c3-4872-b16a-579e4fe463d8.png" alt="image" />
쿠버네티스의 구조는 다음과 같이 워커 노드 위에 각 pod들이 배포되는 형식이다.</p>

<p>쿠버네티스 오브젝트에는 pod 뿐 아니라 label, deployment, statefulset, secret 등 다양한 리소스가 있는데 용도와 목적이 다른 수많은 오브젝트들이 배포가 되면 비슷한 이름의 수많은 object들이 생기게 될 것이고 이로인해 사용과 관리 측면에서 어려움을 느낄 수 있다.</p>

<p>이를 방지하기 위해 namespace라는 것을 제공한다.</p>

<p>namespace란 쿠버네티스 클러스터 내의 논리적인 분리 단위이다.
<img src="https://user-images.githubusercontent.com/63439911/197184960-45248431-3e03-4949-a20c-e6d4cecb00c5.png" alt="image" />
namespace는 쿠버네티스 오브젝트를 묶는 하나의 가상공간 또는 그룹이다.</p>

<p>다만 isolation은 되지 않는다.</p>

<h3 id="namespace-사용">namespace 사용</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1
kind: Namespace
metadata:
	name: test
spec:
	limits: # 리소스의 기본값과 상한값 등을 지정할 수 있다.
	- default:
			cpu: 1
		defaultRequest:
			cpu: 0.5
		type: Container
</code></pre></div></div>
<p>또한 namespace는 다음과 같은 명령어를 통해 생성이 가능하다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply -f test-namespace.yaml # 혹은
kubectl create namespace test
</code></pre></div></div>

<h3 id="namespace의-목적">namespace의 목적</h3>

<ul>
  <li>
    <p>네임스페이스 별 리소스 할당량 지정<br />
 <img src="https://user-images.githubusercontent.com/63439911/197187510-fd39b5f5-cc25-4a4e-a24e-f71147a0157c.png" alt="image" />
 네임스페이스 별 CPU/GPU 할당량을 조절할 수 있다. 그렇게 하여 자원을 최대한 효율적으로 사용할 수 있다.</p>
  </li>
  <li>
    <p>사용자 별 네임스페이스 접근 권한<br />
사용자 인증 후, 해당 사용자가 api 또는 namespace에 권한이 있는지 체크 후 검증된 사용자만 api를 사용하게 할 수 있다.</p>
  </li>
</ul>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="DevOps" /><summary type="html"><![CDATA[K8s 컴포넌트]]></summary></entry><entry><title type="html">Kubernetes - 쿠버네티스의 특징</title><link href="http://localhost:4000/devops/kubernetes-1/" rel="alternate" type="text/html" title="Kubernetes - 쿠버네티스의 특징" /><published>2022-10-17T00:00:00+09:00</published><updated>2022-10-17T00:00:00+09:00</updated><id>http://localhost:4000/devops/kubernetes-1</id><content type="html" xml:base="http://localhost:4000/devops/kubernetes-1/"><![CDATA[<h1 id="kubernetes">Kubernetes</h1>

<p><img src="https://user-images.githubusercontent.com/63439911/196174608-3ad5f71c-86f4-4c4d-a8d2-f8056d8060bd.png" alt="image" /></p>

<p>전통적인 배포에서 초기 조직은 애플리케이션을 물리 서버에서 실행했다. 물리 서버를 많이 유지하기 위해서 조직에게 많은 비용이 들었다.</p>

<p>가상화된 배포에서는 많은 비용이 드는 전통적인 배포 방식의 단점을 해결하고 가상화를 도입했다. 이를 통해 단일 물리 서버의 CPU에서 여러 가상 시스템(VM)을 실행할 수 있게 했따. 또한 가상화를 통해 VM간에 애플리케이션을 격리하고 그 정보들을 다른 애플리케이션에서 자유롭게 엑세스 할 수 없기 때문에 일정 수준의 보안성이 제공된다.</p>

<p>또한 각각의 VM은 가상화된 하드웨어 상에서 자체 운영체제를 포함한 모든 구성 요소를 실행하는 하나의 완전한 머신이다.</p>

<p>컨테이너 개발에는 VM과 유사하지만 격리 속성을 완화하여 애플리케이션 간에 운영체제를 공유한다. 그렇기 떄문에 가볍다. VM과 마찬가지로 컨테이너에는 자체 파일 시스템, CPU 점유율, 메모리 프로세스 등의 공간이 있다.</p>

<p>다음으로 컨테이너의 장점을 알아보면 다음과 같다.</p>

<ul>
  <li>기민하다.
    <ul>
      <li>VM 이미지를 사용하는 것에 비해 이미지 생성이 쉽고 효율적이다.</li>
    </ul>
  </li>
  <li>지속적인 개발 통합 및 배포
    <ul>
      <li>안정적이고 주기적으로 컨테이너 이미지를 빌드해서 배포할 수 있다. 또한 효율적인 rollback이 가능하다.</li>
    </ul>
  </li>
  <li>개발과 운영의 분리
    <ul>
      <li>배포 시점이 아니라 빌드/릴리스 시점에 컨테이너 이미지를 만들기 때문에 애플리케이션이 infrastructure에서 분리된다.</li>
    </ul>
  </li>
  <li>가시성
    <ul>
      <li>OS 수준의 정보와 메트릭에 머무르지 않는다.</li>
    </ul>
  </li>
  <li>일관성
    <ul>
      <li>로컬환경, 클라우드 환경 모두 동일하게 구동된다.</li>
    </ul>
  </li>
  <li>클라우드 및 OS 배포판 간 이식성
    <ul>
      <li>Ubuntu, CoreOS, On-premise 어디서든 구동된다.</li>
    </ul>
  </li>
  <li>애플리케이션 중심 관리
    <ul>
      <li>가상 하드웨어 상에서 OS를 실행하는 수준에서 논리적인 리소스를 사용하는 OS 상에서 애플리케이션을 실행하는 수준으로 추상화 수준이 높아진다.</li>
    </ul>
  </li>
  <li>분산되고 유연하며 자유로운 마이크로서비스
    <ul>
      <li>단일 목적의 머신에서 모놀리식 스택으로 구동되지 않고 독립적인 단위로 쪼개져서 동적으로 배포하고 관리될 수 있다.</li>
    </ul>
  </li>
  <li>리소스 격리
    <ul>
      <li>애플리케이션의 성능을 예측할 수 있다.</li>
    </ul>
  </li>
  <li>자원 사용량
    <ul>
      <li>리소스 사용량이 고효율이다.
        <h2 id="k8s란">K8s란?</h2>
      </li>
    </ul>
  </li>
</ul>

<p>단일 서버에서 도커를 사용하게 되면 오케스트레이션이라고 불리는 쿠버네티스를 사용할 이유가 없다. 그러나 두 개 이상의 서버에서 도커 데몬을 사용하게 된다면 idle 상태인 서버를 선택하여 해당 서버에 컨테이너를 생성해서 운영해야 한다. 이 때 k8s와 같은 오케스트레이션 툴이 필요하다.</p>

<ul>
  <li>오케스트레이션
    <ul>
      <li>컨테이너의 수가 많아지면 관리와 운영에 어려움이 따르는데 이러한 다수의 컨테이너 실행을 관리 및 조율하는 시스템이다.</li>
    </ul>
  </li>
</ul>

<h2 id="k8s가-필요한-이유">K8s가 필요한 이유</h2>

<p>프로덕션 환경에서는 애플리케이션을 실행하는 컨테이너를 관리하고 가동 중지 시간이 없는지 확인해야 한다. → 예를 들어 컨테이너가 다운되면 다른 컨테이너를 다시 시작해야하는데 이것을 자동으로 처리해야한다.</p>

<p>쿠버네티스는 분산 시스템을 탄력적으로 실행하기 위한 프레임 워크를 제공한다. 애플리케이션의 확장과 장애 조치를 처리하고 배포 패턴 등을 제공한다.</p>

<p>쿠버네티스는 다음과 같은 것들을 제공한다.</p>

<ul>
  <li>서비스 디스커버리, 로드 밸런싱
    <ul>
      <li>쿠버네티스는 DNS 이름을 사용하거나 자체 IP 주소를 사용하여 컨테이너를 노출한다. 컨테이너에 대한 트래픽이 많으면 그것들을 로드밸런싱하여 배포가 안정적으로 이뤄지게 한다.</li>
    </ul>
  </li>
  <li>스토리지 오케스트레이션
    <ul>
      <li>로컬 저장소, 공용 클라우드 공급자 등과 같이 원하는 저장소 시스템을 자동으로 탐재 가능하다.</li>
    </ul>
  </li>
  <li>자동화된 롤아웃과 롤백
    <ul>
      <li>배포된 컨테이너의 원하는 상태를 서술하고 현재 상태를 원하는 상태로 설정한 속도에 따라 변경할 수 있다. → 배포용 새 컨테이너를 만들고 기존 것을 제거하고 옮길 수 있다.</li>
    </ul>
  </li>
  <li>자동화된 빈 패킹
    <ul>
      <li>각 컨테이너가 필요로 하는 CPU와 RAM을 쿠버네티스에게 지시한다. 쿠버네티스는 컨테이너를 노드에 맞추어서 리소스를 가장 잘 사용할 수 있도록 해준다.</li>
    </ul>
  </li>
  <li>자동화된 복구
    <ul>
      <li>실패한 컨테이너를 다시 시작하고 교체한다.</li>
    </ul>
  </li>
  <li>시크릿과 구성 관리
    <ul>
      <li>암호, OAuth 토큰 및 SSH 키와 같은 중요한 정보를 저장하고 관리할 수 있다. 컨테이너 이미지를 재구성하지 않고 스택 구성에 시크릿을 노출하지 않고도 시크릿 및 애플리케이션 구성을 배포 및 업데이트 할 수 있다.
        <h2 id="k8s의-목적">K8s의 목적</h2>
      </li>
    </ul>
  </li>
</ul>

<h3 id="-다중의-도커-서버를-하나의-pool로-구성">| 다중의 도커 서버를 하나의 Pool로 구성</h3>

<p>K8s는 다중 서버의 도커 데몬에 연결하여 사용하는데 사용자는 사용하는 서버의 서버가 몇 개인지 도커 컨테이너가 몇 개 실행중인지 알 필요가 없다.</p>

<p>단지 마스터에게 사용자가 필요한 컨테이너를 어떤 목적에 맞는 이미지로 몇 개 만들지만 명령하면 된다.</p>

<h3 id="-다중-서버에-분산되어-컨테이너-생성">| 다중 서버에 분산되어 컨테이너 생성</h3>
<p><img src="https://user-images.githubusercontent.com/63439911/196420747-87fb2f40-45ef-4582-85ec-d2ebada342d9.png" alt="image" />
두 개의 워커 노드에 3개의 container를 생성하게 되면 쿠버네티스에서 알아서 컨테이너를 A서버와 B서버에게 할당한다. idle인 서버를 직접 찾지 않아도 된다.</p>

<h3 id="-a서버-b서버-와의-컨테이너-통신">| A서버 B서버 와의 컨테이너 통신</h3>

<p>각 서버 컨테이너는 각각의 private ip가 있는데 이러한 컨테이너들간의 통신은 kube-proxy 등을 통해 가능하다.</p>

<h3 id="-컨테이너-재생성">| 컨테이너 재생성</h3>

<p>서버에 문제가 생기거나 컨테이너가 exit 되는 경우 쿠버네티스는 이 상황을 방지하여 동일한 컨테이너를 생성하고 서비스를 지속적으로 제공한다.</p>

<h3 id="-load-balance">| Load Balance</h3>

<p>kubernetes 클러스터로 생성된 웹사이트에 3개의 컨테이너가 동작하는데 그 웹사이트의 public ip로 사용자가 접근할 때마다 컨테이너 순서대로 접근할 수 있도록 round-robin 형태의 로드밸런싱이 제공된다.</p>

<h2 id="k8s-특징">K8s 특징</h2>

<p>쿠버네티스는 컨테이너 수준에서 운영되기 때문에 PaaS가 일반적으로 제공하는 배포, 스케일링, 로드 밸런싱과 같은 기능을 제공하며, 사용자가 로깅, 모니터링 및 알림 솔루션을 통합할 수 있다. 개발자가 플랫폼을 만드는 구성 요소를 제공하지만, 필요한 경우 사용자의 선택권과 유연성을 지켜준다.</p>

<ul>
  <li>쿠버네티스는 stateless, stateful, 데이터 처리를 위한 워크로드르 포함한 다양한 워크로드를 지원하는 것을 목표로 한다.</li>
  <li>소스 코드를 배포하지 않으며 애플리케이션을 빌드하지 않는다. CI/CD 워크플로우는 조직 문화와 취향에 따르고 기술적인 요구사항으로 결정된다.</li>
  <li>애플리케이션 레벨의 서비스를 제공하지 않는다. 애플리케이션 서비스에는 미들웨어, 데이터 처리 프레임워크, 데이터베이스, 캐시 또는 클러스터 스토리지 시스템 등이 있다.</li>
  <li>로깅, 모니터링 또는 경보 솔루션을 포함하지 않는다.</li>
</ul>

<p>쿠버네티스는 오케스트레이션의 필요성을 없애준다. 오케스트레이션이란 A를 먼저 한 다음 B를 하고 C를 하느 것과 같이 정의된 워크플로우를 수행하는 것이다.</p>

<p>쿠버네티스는 독립적이고 조합 가능한 제어 프로세스들로 구성되어 있다. 이 프로세스는 지속적으로 현재 상태를 입력받은 의도한 상태로 나아가도록 한다. 이로써 시스템이 보다 더 사용하기 쉬워지고 강력해지며 견고하고 회복력을 갖추게 되며 확장 가능해진다.</p>

<h2 id="k8s-용어">K8s 용어</h2>

<ul>
  <li>master
    <ul>
      <li>마스터 노드이며 도커 데몬을 관리하는 역할</li>
    </ul>
  </li>
  <li>worker
    <ul>
      <li>도커가 설치되어 있으며 실제 컨테이너들이 생성되어 일하는 노드이다. master의 관리를 받는다.</li>
    </ul>
  </li>
  <li>pod
    <ul>
      <li>k8s의 기본 단위이다. 컨테이너 혹은 컨테이너의 묶음이다.</li>
    </ul>
  </li>
  <li>rc
    <ul>
      <li>replication controller로 pod를 자동으로 생성 복제해주는 컨트롤러이다. 복제 개수 설정을 3으로 하면 3개의 pod가 서비스상에 계속 active상태가 된다.</li>
    </ul>
  </li>
  <li>service
    <ul>
      <li>pod의 group을 식별하는 라벨이라는 기준에 따라 pod들을 하나의 서비스로 외부에서 접근할 수 있게함</li>
    </ul>
  </li>
  <li>yaml
    <ul>
      <li>k8s에서 service, rc, pod등 기능을 설명한 데이터 형식 코드이다.</li>
    </ul>
  </li>
</ul>

<h2 id="k8s-주요-도구">K8s 주요 도구</h2>
<p><img src="https://user-images.githubusercontent.com/63439911/196420924-63e71c1c-69a4-4e14-a14d-d280644a5ea1.png" alt="image" /></p>
<ul>
  <li>
    <p>kubeadm: init(join), 초기화(Bootstrap)</p>

    <p>kubernetes 구성과 초기화 그리고 노드 확장할 때 외에는 사용하지 않지만 중요한 요소이다.</p>
  </li>
  <li>
    <p>kubectl : cmd 작업 수행, k8s object 생성,관리</p>
    <h2 id="k8s-pod">K8s pod</h2>
    <p><img src="https://user-images.githubusercontent.com/63439911/196421075-c91721f6-4da4-4e42-8a2a-acd51beaaf6c.png" alt="image" />
pod란 k8s의 기본적인 배포단위이며, 컨테이너를 포함한 단위이다. k8s의 특징 중 하나는 container를 개별적으로 하나씩 배포하는 것이 아니라 pod 단위로 배포한다.</p>
  </li>
</ul>

<h2 id="pod---replicaset">pod - replicaset</h2>
<p><img src="https://user-images.githubusercontent.com/63439911/196421191-3bd38cda-0cb2-42c9-910d-86555a5b3bc5.png" alt="image" /><img src="https://user-images.githubusercontent.com/63439911/196421216-c651d847-b2d6-4334-9324-9ecbed49da5b.png" alt="image" />
web container 2개 복제해서 띄어놓겠다고 정의하여 pod를 생성하게 되면 2개의 호스트에 container가 생성되어 서비스를 한다.</p>

<h2 id="랜처">랜처</h2>
<p>대규모 클러스터 및 기업용 환경에도 적합한 쿠버네티스 관리 플랫폼이다. 오픈소스이다.</p>

<p>랜처의 가장 큰 장점으로는 쿠버네티스 클러스터뿐 아니라 운영에 필요한 모니터링, 보안 관련 기능을 쉽게 설치할 수 있다는 점이다. 랜처의 관리 도구를 사용해서 새로운 쿠버네티스 클러스터를 쉽게 생성하고 여러 클러스터를 한 곳에서 관리할 수 있다.
<img width="702" alt="image" src="https://user-images.githubusercontent.com/63439911/197162299-2cfa3078-7312-4d59-9daa-67cea8d88c6c.png" />
랜처는 대규모 시스템 관리까지 염두에 둔 플랫폼이므로 자체적인 구성 요소가 많이 포함되어 있으며 이로 인해 다른 도구에 비해 더 무거운 단점이 있다.</p>

<table>
  <tbody>
    <tr>
      <td>랜처의 특징</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>용도 : 대규모 기업용 환경에도 활용 가능한 다목적 쿠버네티스 관리 플랫폼</li>
  <li>장점 : 기능이 많고 추가 도구 설치 용이, 멀티 클라우드 관리 가능</li>
  <li>단점 : 다른 도구에 비해 무겁다.</li>
</ul>

<h2 id="k8s-vs-rancher">K8s vs Rancher</h2>

<ul>
  <li>
    <p>K8s</p>

    <p>K8s는 컨테이너 오케스트레이션의 중심역할을한다.</p>

    <p>여러 퍼블릭 클라우드 공급자 및 하이브리드 클라우드 환경에서 컨테이너화된 워크로드를 효율적으로 실행할 수 있는 유연성을 팀에게 제공한다.</p>

    <p>K8s는 더 발전된 스케쥴링과 scaling 기능을 제공하여 application 성능과 고가용성을 보장한다.</p>

    <p>그러나 해당 기능은 클러스터 내의 자원 관리에 중점을 둔다.</p>

    <ul>
      <li>특징
        <ul>
          <li>클라우드 공급자에 구애받지 않음
            <ul>
              <li>K8s는 오픈소스이고 플랫폼에 구애받지 않고 workload가 중앙화되어있고 public cloud 플랫폼 간의 k8s의 핵심 기능이 유사하기 때문에 cloud 제공자들간 이식이 자유롭다.</li>
            </ul>
          </li>
          <li>손쉬운 application 확장 가능
            <ul>
              <li>K8s는 각각 cluster 자동 확장기와 pod 자동확장기를 사용하여 리소스 및 서비스 확장 프로세스를 자동화한다. (autoscaling)</li>
              <li>autoscaling은 관리자와 응용 프로그램 개발자가 으용 프로그램을 수평 또는 수직적으로 확장하여 급증하는 트래픽에 대응이 가능하게 해준다.</li>
              <li>트래픽이 적은 기간에는 자동적으로 축소되어 비용을 절감할 수 있다.</li>
            </ul>
          </li>
          <li>자원 사용 최적화
            <ul>
              <li>관리자는 node의 위치, 하드웨어 성능 또는 이미 동일한 node에서 hosting 되는 다른 pod에 대한 반선호도를 사용하여 pod를 예약할 수 있다.</li>
              <li>이러한 고급 스케쥴링 기술을 통해 hosting platform 활용을 효율적이고 비용 효율적으로 만들 수 있다.</li>
            </ul>
          </li>
          <li>복원
            <ul>
              <li>pod 및 node 장애에 대한 복원력이 뛰어나도록 설계되었을 뿐 아니라 서로 다른 public cloud 가용 영역 또는 물리적 데이터 센터에 있는 VM pod를 예약하여 배포를 지원한다.</li>
            </ul>
          </li>
          <li>일관성 있는 환경 유지
            <ul>
              <li>K8s는 application 배포의 여러 단계 동안 환경이 일관되도록 보장한다.</li>
              <li>또한 온프레미스에 있는 클라우드 공급자와 서버 간에 일관성을 보장한다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Rancher</p>

    <p>Rancher는 K8s가 단일 클러스터 내의 자원 관리에 중점을 두는것과는 다르게 여러 K8s 클러스터를 관리하도록 설계된 플랫폼이다.</p>

    <p>Rancher는 Prometheus를 활용하여 cluster provisioning, centralizaed security 관리 및 workload 모니터링과 같은 작업들을 단순화한다.</p>

    <p>또한 Kubecost, Prometheus, Grafana 및 MySQL과 같은 다양한 어플리케이션을 위한 광범위한 Helm Chart application catalog를 제공한다.</p>

    <ul>
      <li>특징
        <ul>
          <li>cluster provisioning &amp; import
            <ul>
              <li>Rancher를 사용하면 단일 콘솔을 사용하여 선호하는 클라우드 공급자에 K8s 클러스터를 provisioning할 수 있다.</li>
              <li>Rancher를 사용하면 GCP, AWS, Azure 콘솔 간에 전환할 필요가 없다.</li>
              <li>기존 클러스터가 있고 이를 관리하기 위해 Rancher를 사용하는 경우 Cluster Import라는 옵션을 제공하고 Rancher가 관리를 인계하는 데 도움이 되는 기존 클러스터 노드에 에이전트를 배포한다.</li>
            </ul>
          </li>
          <li>프로젝트의 개념
            <ul>
              <li>Namespace는 일반적으로 독립적인 관리 제어가 필요한 별도의 팀에 할당된 클러스터 리소스 그룹이다. Rancher는 Project라고 하는 기존 K8s namespace위에 구성을 제공하고 Project는 namespace를 함께 그룹화하여 단일 제어 지점을 제공한다.</li>
              <li>클러스터 관리자는 namespace로 가는 프로젝트에 role based access control 이라고하는 RBAC를 적용할 수 있다. 이를 통해 모든 namespace 내에서 사용자를 관리할 필요가 없다.</li>
              <li>Rancher는 또한 특정 project의 리소스 사용량에 대해 시각화하고 유용한 운영 지표를 제공한다.</li>
            </ul>
          </li>
          <li>확장된 RBAC 제어
            <ul>
              <li>대부분의 팀은 production에서 둘 이상의 K8s 클러스터를 실행한다. 이러한 workload 분산은 단일 application이 각각 다른 public 및 private cloud에서 호스팅될 수 있는 여러 cluster에 걸쳐 있을 수 있다는 것을 의미한다.</li>
              <li>Rancher는 K8s 클러스터 전체에서 프로젝트 수준 RBAC 제어를 확장한다.</li>
              <li>단일 사용자는 클러스터 간에 전환하기 위해 다른 인증 키 없이 여러 K8s 클러스터에서 동일하거나 다른 권한을 갖도록 정의할 수 있다.</li>
            </ul>
          </li>
          <li>손쉬운 workload 배포
            <ul>
              <li>복잡한 배포 Manifest를 생성하지 않고 Rancher UI를 사용하여 Cluster에 workload를 배포할 수 있따.</li>
              <li>YAML template를 사용하여 구성하는 모든 옵션은 UI에서 사용할 수 있다.</li>
            </ul>
          </li>
          <li>모니터링과 alert
            <ul>
              <li>모니터링 및 Alert는 Prometheus 및 Alertmanager와 같이 인기 있고 검증된 도구 위에서 구축된다.</li>
              <li>구성원을 쉽게 추가할 수 있는 RBAC 제어가 포함된 대시보드를 제공한다.</li>
            </ul>
          </li>
          <li>광범위한 application catalog
            <ul>
              <li>Helm Chart를 사용하여 클러스터에서 인기 있는 Application의 배포를 단순화하는 광범위한 catalog가 있다. 스마트폰의 앱 스토어와 유사하다.</li>
              <li>수동으로 manifest 파일을 update하는 것과 같이 기존 방법을 사용하여 K8s에 배포하는 것 대신 Rancher를 사용하면 여러 클러스터에 Application을 쉽게 배포할 수 있다.</li>
              <li>K8s 및 Rancher는 컨테이너를 오케스트레이션하고 여러 K8s 클러스터에서 효율적으로 수행하는 데 필요한 모든 기능을 제공한다. 그러나 이러한 대규모 환경에 내재된 비용 관리 문제는 해결하지 못한다. Rancher는 Kubecost와 호환되어 다중 클러스터 비용 할당 문제에 대한 자동화된 솔루션을 제공한다.</li>
            </ul>
          </li>
          <li>K8s를 위한 비용 관리
            <ul>
              <li>Helm chart의 Rancher application catalog에서 간단하게 Kubecost를 배포할 수 있다.</li>
              <li>Kubecost는 단일 Rancher 프로젝트에서 여러 namespace에 걸쳐 application을 그룹화 할 때 Rancher 프로젝트에 대한 비용을 할당하는 데 도움을 줄 수 있다. 또한 Pod label의 도움으로 Kubecost는 K8s 리소스에서 사용하는 public cloud의 데이터베이스 서비스와 같은 외부 리소스 비용도 고려한다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>김기훈</name><email>tega1996@naver.com</email></author><category term="DevOps" /><summary type="html"><![CDATA[Kubernetes]]></summary></entry></feed>